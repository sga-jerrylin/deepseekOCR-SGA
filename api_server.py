"""
DeepSeek-OCR FastAPI Server
æä¾› RESTful API æ¥å£ç”¨äºå›¾ç‰‡å’Œ PDF çš„ OCR å¤„ç†
"""

import os
# ç¦ç”¨ torch.compile å’Œ JIT ç¼–è¯‘,é¿å… CUDA æ¶æ„ä¸å…¼å®¹é—®é¢˜
os.environ["PYTORCH_JIT"] = "0"
os.environ["PYTORCH_NVFUSER_DISABLE"] = "1"
os.environ["TORCH_COMPILE_DISABLE"] = "1"

from fastapi import FastAPI, File, UploadFile, HTTPException, Form
from fastapi.responses import FileResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List
import torch
import os
import tempfile
import base64
from pathlib import Path
import logging
from datetime import datetime, timedelta
import uvicorn
import asyncio
import gc
import threading
import re
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from io import BytesIO
import fitz  # PyMuPDF - ç”¨äº PDF å¤„ç†

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="DeepSeek-OCR API",
    description="åŸºäº DeepSeek-OCR çš„å…‰å­¦å­—ç¬¦è¯†åˆ«æœåŠ¡",
    version="1.0.0"
)

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡å­˜å‚¨æ¨¡å‹
model = None
tokenizer = None
MODEL_LOADED = False
last_request_time = None
model_load_lock = threading.Lock()

# ==================== é…ç½® ====================
MODEL_NAME = os.getenv("MODEL_NAME", "deepseek-ai/DeepSeek-OCR")
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# è¾“å‡ºç›®å½•é…ç½®
OUTPUT_DIR = Path(os.getenv("OUTPUT_DIR", "./outputs"))
OUTPUT_DIR.mkdir(exist_ok=True)

# è¾“å‡ºæ–‡ä»¶ä¿ç•™æ—¶é—´ï¼ˆç§’ï¼‰- é»˜è®¤ 24 å°æ—¶
OUTPUT_FILE_RETENTION = int(os.getenv("OUTPUT_FILE_RETENTION", str(24 * 3600)))

# ç©ºé—²è¶…æ—¶é…ç½®ï¼ˆç§’ï¼‰
IDLE_TIMEOUT = int(os.getenv("IDLE_TIMEOUT", "3600"))  # é»˜è®¤ 1 å°æ—¶
LAZY_LOAD = os.getenv("LAZY_LOAD", "true").lower() == "true"  # æ˜¯å¦å¯ç”¨æŒ‰éœ€åŠ è½½

# ==================== å¹¶å‘æ§åˆ¶é…ç½® ====================
# æœ€å¤§å¹¶å‘è¯·æ±‚æ•°ï¼ˆé˜²æ­¢ GPU æº¢å‡ºï¼‰
MAX_CONCURRENT_REQUESTS = int(os.getenv("MAX_CONCURRENT_REQUESTS", "1"))
# æœ€å¤§æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰- é»˜è®¤ 20MB
MAX_FILE_SIZE = int(os.getenv("MAX_FILE_SIZE", str(20 * 1024 * 1024)))
# å¹¶å‘æ§åˆ¶ä¿¡å·é‡
request_semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
# å½“å‰å¤„ç†ä¸­çš„è¯·æ±‚æ•°
active_requests = 0
active_requests_lock = threading.Lock()

# ==================== API åŸºç¡€ URL é…ç½® ====================
# ç”¨äºç”Ÿæˆå®Œæ•´çš„æ–‡ä»¶è®¿é—® URL
# å¦‚æœéƒ¨ç½²åœ¨å…¬ç½‘ï¼Œè®¾ç½®ä¸ºå…¬ç½‘åœ°å€ï¼Œä¾‹å¦‚: "https://your-domain.com"
# å¦‚æœä½¿ç”¨å†…ç½‘ç©¿é€ï¼Œè®¾ç½®ä¸ºç©¿é€åçš„åœ°å€ï¼Œä¾‹å¦‚: "https://your-tunnel.com"
API_BASE_URL = os.getenv("API_BASE_URL", "http://localhost:8200")


class OCRRequest(BaseModel):
    """OCR è¯·æ±‚æ¨¡å‹"""
    prompt: Optional[str] = "<image>\n<|grounding|>Convert the document to markdown."
    base_size: Optional[int] = 1024
    image_size: Optional[int] = 640
    crop_mode: Optional[bool] = True
    save_results: Optional[bool] = False
    test_compress: Optional[bool] = True


class OCRResponse(BaseModel):
    """OCR å“åº”æ¨¡å‹ï¼ˆçº¯æ–‡æœ¬ç‰ˆï¼Œä¿ç•™å‘åå…¼å®¹ï¼‰"""
    success: bool
    text: Optional[str] = None
    error: Optional[str] = None
    processing_time: Optional[float] = None
    metadata: Optional[dict] = None
    image_with_boxes_url: Optional[str] = None  # å·²åºŸå¼ƒï¼Œå§‹ç»ˆä¸º None
    extracted_images_urls: Optional[List[str]] = None  # å·²åºŸå¼ƒï¼Œå§‹ç»ˆä¸º None


class BoundingBox(BaseModel):
    """è¾¹ç•Œæ¡†ä¿¡æ¯"""
    id: str  # æ¡†çš„å”¯ä¸€ ID
    label_type: str  # æ ‡ç­¾ç±»å‹ï¼šimage, title, paragraph, table ç­‰
    # å½’ä¸€åŒ–åæ ‡ (0-1)
    x1: float
    y1: float
    x2: float
    y2: float
    # åƒç´ åæ ‡
    x1_px: int
    y1_px: int
    x2_px: int
    y2_px: int


class Region(BaseModel):
    """æå–çš„å›¾ç‰‡åŒºåŸŸ"""
    id: str  # åŒºåŸŸ ID
    label_type: str  # æ ‡ç­¾ç±»å‹
    page_number: Optional[int] = None  # é¡µç ï¼ˆPDF æ—¶æœ‰æ•ˆï¼‰
    bbox: Optional[BoundingBox] = None  # è¾¹ç•Œæ¡†ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
    image_url: str  # è£å‰ªåçš„å­å›¾ URL
    text: Optional[str] = None  # è¯¥åŒºåŸŸå¯¹åº”çš„æ–‡å­—å†…å®¹


class OCRBoxesResponse(BaseModel):
    """ç”»æ¡† API å“åº”æ¨¡å‹"""
    success: bool
    image_with_boxes_url: str  # ç”»å¥½æ¡†çš„æ•´å›¾ URL
    boxes: List[BoundingBox]  # æ‰€æœ‰æ¡†çš„ç»“æ„åŒ–ä¿¡æ¯
    text: Optional[str] = None  # æ•´é¡µ OCR æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
    question: str  # å›æ˜¾ prompt
    labels_summary: List[str]  # æ£€æµ‹åˆ°çš„æ ‡ç­¾ç±»å‹åˆ—è¡¨
    processing_time: float
    metadata: dict
    error: Optional[str] = None


class OCRExtractResponse(BaseModel):
    """æå– API å“åº”æ¨¡å‹"""
    success: bool
    text: Optional[str] = None  # æ•´é¡µ OCR æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
    regions: List[Region]  # æå–çš„å›¾ç‰‡åŒºåŸŸåˆ—è¡¨
    question: str  # å›æ˜¾ prompt
    processing_time: float
    metadata: dict
    error: Optional[str] = None


def re_match(text):
    """æå– OCR ç»“æœä¸­çš„å¼•ç”¨å’Œæ£€æµ‹æ ‡ç­¾"""
    pattern = r'(<\|ref\|>(.*?)<\|/ref\|><\|det\|>(.*?)<\|/det\|>)'
    matches = re.findall(pattern, text, re.DOTALL)

    # åˆ†ç±»ï¼šå›¾ç‰‡ç±»å‹å’Œå…¶ä»–ç±»å‹
    matches_image = []
    matches_other = []
    for a_match in matches:
        if '<|ref|>image<|/ref|>' in a_match[0]:
            matches_image.append(a_match[0])
        else:
            matches_other.append(a_match[0])

    return matches, matches_image, matches_other


def is_pdf(file_content: bytes) -> bool:
    """æ£€æµ‹æ–‡ä»¶æ˜¯å¦ä¸º PDF"""
    return file_content[:4] == b'%PDF'


def pdf_to_images(pdf_content: bytes, dpi: int = 200) -> List[Image.Image]:
    """
    å°† PDF è½¬æ¢ä¸ºå›¾ç‰‡åˆ—è¡¨

    Args:
        pdf_content: PDF æ–‡ä»¶å†…å®¹ï¼ˆå­—èŠ‚ï¼‰
        dpi: æ¸²æŸ“ DPIï¼ˆé»˜è®¤ 200ï¼Œè¶Šé«˜è¶Šæ¸…æ™°ä½†è¶Šæ…¢ï¼‰

    Returns:
        å›¾ç‰‡åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€é¡µçš„ PIL Image
    """
    try:
        # ä»å­—èŠ‚æµæ‰“å¼€ PDF
        pdf_document = fitz.open(stream=pdf_content, filetype="pdf")
        images = []

        for page_num in range(len(pdf_document)):
            page = pdf_document[page_num]

            # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼ˆDPI / 72ï¼‰
            zoom = dpi / 72
            mat = fitz.Matrix(zoom, zoom)

            # æ¸²æŸ“é¡µé¢ä¸ºå›¾ç‰‡
            pix = page.get_pixmap(matrix=mat)

            # è½¬æ¢ä¸º PIL Image
            img_data = pix.tobytes("png")
            img = Image.open(BytesIO(img_data))
            images.append(img)

            logger.info(f"ğŸ“„ PDF ç¬¬ {page_num + 1}/{len(pdf_document)} é¡µè½¬æ¢å®Œæˆ")

        pdf_document.close()
        return images

    except Exception as e:
        logger.error(f"âŒ PDF è½¬æ¢å¤±è´¥: {e}")
        raise HTTPException(status_code=400, detail=f"PDF è½¬æ¢å¤±è´¥: {str(e)}")


def extract_coordinates_and_label(ref_text, image_width, image_height):
    """ä»å¼•ç”¨æ–‡æœ¬ä¸­æå–åæ ‡å’Œæ ‡ç­¾"""
    try:
        label_type = ref_text[1]
        cor_list = eval(ref_text[2])
    except Exception as e:
        logger.error(f"æå–åæ ‡å¤±è´¥: {e}")
        return None
    return (label_type, cor_list)


def _parse_boxes_from_text(ocr_text: str, image_width: int, image_height: int) -> List[BoundingBox]:
    """ä» OCR æ–‡æœ¬ä¸­è§£ææ‰€æœ‰è¾¹ç•Œæ¡†ä¿¡æ¯

    Args:
        ocr_text: OCR è¯†åˆ«ç»“æœæ–‡æœ¬
        image_width: å›¾ç‰‡å®½åº¦ï¼ˆåƒç´ ï¼‰
        image_height: å›¾ç‰‡é«˜åº¦ï¼ˆåƒç´ ï¼‰

    Returns:
        BoundingBox å¯¹è±¡åˆ—è¡¨
    """
    matches, _, _ = re_match(ocr_text)
    boxes = []

    for i, ref in enumerate(matches):
        try:
            result = extract_coordinates_and_label(ref, image_width, image_height)
            if result:
                label_type, points_list = result

                for j, points in enumerate(points_list):
                    x1_norm, y1_norm, x2_norm, y2_norm = points

                    # è½¬æ¢ä¸ºåƒç´ åæ ‡
                    x1_px = int(x1_norm / 999 * image_width)
                    y1_px = int(y1_norm / 999 * image_height)
                    x2_px = int(x2_norm / 999 * image_width)
                    y2_px = int(y2_norm / 999 * image_height)

                    # è½¬æ¢ä¸º 0-1 å½’ä¸€åŒ–åæ ‡
                    x1 = x1_norm / 999
                    y1 = y1_norm / 999
                    x2 = x2_norm / 999
                    y2 = y2_norm / 999

                    box = BoundingBox(
                        id=f"box_{i}_{j}",
                        label_type=label_type,
                        x1=x1,
                        y1=y1,
                        x2=x2,
                        y2=y2,
                        x1_px=x1_px,
                        y1_px=y1_px,
                        x2_px=x2_px,
                        y2_px=y2_px
                    )
                    boxes.append(box)
        except Exception as e:
            logger.error(f"è§£æè¾¹ç•Œæ¡†å¤±è´¥: {e}")
            continue

    return boxes


def _extract_region_text(ocr_text: str, region_index: int) -> Optional[str]:
    """ä» OCR æ–‡æœ¬ä¸­æå–ç‰¹å®šåŒºåŸŸçš„æ–‡å­—å†…å®¹

    Args:
        ocr_text: OCR è¯†åˆ«ç»“æœæ–‡æœ¬
        region_index: åŒºåŸŸç´¢å¼•

    Returns:
        è¯¥åŒºåŸŸå¯¹åº”çš„æ–‡å­—å†…å®¹ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å› None
    """
    # ç®€å•å®ç°ï¼šæå–æ¯ä¸ª ref/det å—åé¢çš„æ–‡æœ¬ï¼Œç›´åˆ°ä¸‹ä¸€ä¸ª ref æ ‡ç­¾
    pattern = r'<\|ref\|>(.*?)<\|/ref\|><\|det\|>(.*?)<\|/det\|>(.*?)(?=<\|ref\||$)'
    matches = re.findall(pattern, ocr_text, re.DOTALL)

    if region_index < len(matches):
        text_content = matches[region_index][2].strip()
        return text_content if text_content else None

    return None


def draw_bounding_boxes(image: Image.Image, ocr_text: str, extract_images: bool = False,
                       save_to_disk: bool = True, filename_prefix: str = "result") -> tuple:
    """åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶è¾¹ç•Œæ¡†ï¼Œå¹¶å¯é€‰æå–å›¾ç‰‡åŒºåŸŸ

    Args:
        image: PIL Image å¯¹è±¡
        ocr_text: OCR è¯†åˆ«ç»“æœæ–‡æœ¬ï¼ˆåŒ…å« <|ref|> å’Œ <|det|> æ ‡ç­¾ï¼‰
        extract_images: æ˜¯å¦æå–å›¾ç‰‡åŒºåŸŸ
        save_to_disk: æ˜¯å¦ä¿å­˜åˆ°ç£ç›˜
        filename_prefix: æ–‡ä»¶åå‰ç¼€

    Returns:
        (å¸¦è¾¹ç•Œæ¡†çš„å›¾ç‰‡æ–‡ä»¶è·¯å¾„æˆ–PIL Image, æå–çš„å›¾ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨æˆ–PIL Imageåˆ—è¡¨)
    """
    matches, matches_image, matches_other = re_match(ocr_text)
    if not matches:
        logger.warning("æœªæ‰¾åˆ°è¾¹ç•Œæ¡†ä¿¡æ¯")
        if save_to_disk:
            return None, []
        else:
            return image, []

    image_width, image_height = image.size
    img_draw = image.copy()
    draw = ImageDraw.Draw(img_draw)

    # åˆ›å»ºåŠé€æ˜è¦†ç›–å±‚
    overlay = Image.new('RGBA', img_draw.size, (0, 0, 0, 0))
    draw2 = ImageDraw.Draw(overlay)

    font = ImageFont.load_default()

    # å­˜å‚¨æå–çš„å›¾ç‰‡
    extracted_images = []
    img_idx = 0

    for i, ref in enumerate(matches):
        try:
            result = extract_coordinates_and_label(ref, image_width, image_height)
            if result:
                label_type, points_list = result

                # éšæœºé¢œè‰²
                color = (np.random.randint(0, 200), np.random.randint(0, 200), np.random.randint(0, 255))
                color_a = color + (20,)  # åŠé€æ˜

                for points in points_list:
                    x1, y1, x2, y2 = points

                    # åæ ‡å½’ä¸€åŒ–ï¼ˆDeepSeek-OCR ä½¿ç”¨ 0-999 èŒƒå›´ï¼‰
                    x1 = int(x1 / 999 * image_width)
                    y1 = int(y1 / 999 * image_height)
                    x2 = int(x2 / 999 * image_width)
                    y2 = int(y2 / 999 * image_height)

                    # æå–å›¾ç‰‡åŒºåŸŸï¼ˆå¦‚æœæ˜¯ image ç±»å‹ä¸”éœ€è¦æå–ï¼‰
                    if label_type == 'image' and extract_images:
                        try:
                            cropped = image.crop((x1, y1, x2, y2))
                            extracted_images.append(cropped)
                            img_idx += 1
                        except Exception as e:
                            logger.error(f"æå–å›¾ç‰‡å¤±è´¥: {e}")

                    try:
                        # ç»˜åˆ¶è¾¹ç•Œæ¡†
                        if label_type == 'title':
                            draw.rectangle([x1, y1, x2, y2], outline=color, width=4)
                            draw2.rectangle([x1, y1, x2, y2], fill=color_a, outline=(0, 0, 0, 0), width=1)
                        else:
                            draw.rectangle([x1, y1, x2, y2], outline=color, width=2)
                            draw2.rectangle([x1, y1, x2, y2], fill=color_a, outline=(0, 0, 0, 0), width=1)

                        # ç»˜åˆ¶æ ‡ç­¾
                        text_x = x1
                        text_y = max(0, y1 - 15)

                        text_bbox = draw.textbbox((0, 0), label_type, font=font)
                        text_width = text_bbox[2] - text_bbox[0]
                        text_height = text_bbox[3] - text_bbox[1]
                        draw.rectangle([text_x, text_y, text_x + text_width, text_y + text_height],
                                     fill=(255, 255, 255, 30))

                        draw.text((text_x, text_y), label_type, font=font, fill=color)
                    except Exception as e:
                        logger.error(f"ç»˜åˆ¶è¾¹ç•Œæ¡†å¤±è´¥: {e}")
                        pass
        except Exception as e:
            logger.error(f"å¤„ç†å¼•ç”¨å¤±è´¥: {e}")
            continue

    # åˆå¹¶è¦†ç›–å±‚
    img_draw.paste(overlay, (0, 0), overlay)

    # å¦‚æœéœ€è¦ä¿å­˜åˆ°ç£ç›˜
    if save_to_disk:
        import uuid
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        unique_id = str(uuid.uuid4())[:8]

        # ä¿å­˜å¸¦è¾¹ç•Œæ¡†çš„å›¾ç‰‡
        boxes_filename = f"{filename_prefix}_boxes_{timestamp}_{unique_id}.jpg"
        boxes_path = OUTPUT_DIR / boxes_filename
        img_draw.save(boxes_path, 'JPEG', quality=95)
        logger.info(f"âœ… ä¿å­˜å¸¦è¾¹ç•Œæ¡†çš„å›¾ç‰‡: {boxes_path}")

        # ä¿å­˜æå–çš„å›¾ç‰‡
        extracted_paths = []
        for idx, extracted_img in enumerate(extracted_images):
            extracted_filename = f"{filename_prefix}_extracted_{idx+1}_{timestamp}_{unique_id}.jpg"
            extracted_path = OUTPUT_DIR / extracted_filename
            extracted_img.save(extracted_path, 'JPEG', quality=95)
            extracted_paths.append(f"/outputs/{extracted_filename}")
            logger.info(f"âœ… ä¿å­˜æå–çš„å›¾ç‰‡: {extracted_path}")

        return f"/outputs/{boxes_filename}", extracted_paths
    else:
        return img_draw, extracted_images


def load_model():
    """åŠ è½½ DeepSeek-OCR æ¨¡å‹"""
    global model, tokenizer, MODEL_LOADED, last_request_time

    with model_load_lock:
        if MODEL_LOADED:
            logger.info("æ¨¡å‹å·²åŠ è½½ï¼Œè·³è¿‡é‡å¤åŠ è½½")
            return

        try:
            load_start = datetime.now()
            logger.info(f"ğŸš€ å¼€å§‹åŠ è½½æ¨¡å‹: {MODEL_NAME}")
            logger.info(f"ğŸ“ ä½¿ç”¨è®¾å¤‡: {DEVICE}")

            from transformers import AutoModel, AutoTokenizer

            logger.info("â³ åŠ è½½ tokenizer...")
            tokenizer = AutoTokenizer.from_pretrained(
                MODEL_NAME,
                trust_remote_code=True
            )

            logger.info("â³ åŠ è½½æ¨¡å‹æƒé‡...")
            model = AutoModel.from_pretrained(
                MODEL_NAME,
                attn_implementation='eager',  # ä½¿ç”¨ eager æ¨¡å¼ï¼Œä¸ä½¿ç”¨ Flash Attention
                trust_remote_code=True,
                use_safetensors=True
            )

            logger.info("â³ ç§»åŠ¨æ¨¡å‹åˆ° GPU...")
            model = model.eval()
            if DEVICE == "cuda":
                # å…ˆè½¬æ¢ä¸º bfloat16ï¼Œå†ç§»åˆ° GPUï¼ˆé¿å… CUDA å…¼å®¹æ€§é—®é¢˜ï¼‰
                model = model.to(torch.bfloat16).to(DEVICE)
            else:
                model = model.to(DEVICE)

            MODEL_LOADED = True
            last_request_time = datetime.now()

            load_time = (datetime.now() - load_start).total_seconds()
            logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼è€—æ—¶: {load_time:.2f} ç§’")

            # æ˜¾ç¤º GPU å†…å­˜ä½¿ç”¨æƒ…å†µ
            if DEVICE == "cuda":
                memory_allocated = torch.cuda.memory_allocated() / 1024**3
                memory_reserved = torch.cuda.memory_reserved() / 1024**3
                logger.info(f"ğŸ’¾ GPU å†…å­˜: å·²åˆ†é… {memory_allocated:.2f} GB, å·²ä¿ç•™ {memory_reserved:.2f} GB")

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            raise


def unload_model():
    """å¸è½½æ¨¡å‹é‡Šæ”¾ GPU å†…å­˜"""
    global model, tokenizer, MODEL_LOADED

    with model_load_lock:
        if not MODEL_LOADED:
            logger.info("æ¨¡å‹æœªåŠ è½½ï¼Œæ— éœ€å¸è½½")
            return

        try:
            logger.info("ğŸ”„ å¼€å§‹å¸è½½æ¨¡å‹ï¼Œé‡Šæ”¾ GPU å†…å­˜...")

            # ç§»åŠ¨æ¨¡å‹åˆ° CPU å¹¶åˆ é™¤
            if model is not None:
                if DEVICE == "cuda":
                    model = model.cpu()
                del model

            if tokenizer is not None:
                del tokenizer

            # æ¸…ç† GPU ç¼“å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()

            # å¼ºåˆ¶ Python åƒåœ¾å›æ”¶
            gc.collect()

            model = None
            tokenizer = None
            MODEL_LOADED = False

            # æ˜¾ç¤ºé‡Šæ”¾åçš„ GPU å†…å­˜
            if torch.cuda.is_available():
                memory_allocated = torch.cuda.memory_allocated() / 1024**3
                memory_reserved = torch.cuda.memory_reserved() / 1024**3
                logger.info(f"ğŸ’¾ GPU å†…å­˜é‡Šæ”¾å: å·²åˆ†é… {memory_allocated:.2f} GB, å·²ä¿ç•™ {memory_reserved:.2f} GB")

            logger.info("âœ… æ¨¡å‹å·²å¸è½½ï¼ŒGPU å†…å­˜å·²é‡Šæ”¾")

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹å¸è½½å¤±è´¥: {str(e)}")


async def idle_monitor():
    """åå°ä»»åŠ¡ï¼šç›‘æ§ç©ºé—²æ—¶é—´å¹¶è‡ªåŠ¨å¸è½½æ¨¡å‹"""
    global last_request_time

    logger.info(f"ğŸ” ç©ºé—²ç›‘æ§å·²å¯åŠ¨ï¼Œè¶…æ—¶æ—¶é—´: {IDLE_TIMEOUT} ç§’ ({IDLE_TIMEOUT/60:.1f} åˆ†é’Ÿ)")

    while True:
        await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡

        if MODEL_LOADED and last_request_time:
            idle_time = (datetime.now() - last_request_time).total_seconds()

            if idle_time > IDLE_TIMEOUT:
                logger.info(f"â° æ¨¡å‹ç©ºé—² {idle_time:.0f} ç§’ ({idle_time/60:.1f} åˆ†é’Ÿ)ï¼Œå¼€å§‹å¸è½½...")
                unload_model()
                last_request_time = None


async def cleanup_old_files():
    """å®šæœŸæ¸…ç†è¿‡æœŸçš„è¾“å‡ºæ–‡ä»¶"""
    while True:
        try:
            await asyncio.sleep(3600)  # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡

            current_time = datetime.now().timestamp()
            deleted_count = 0

            for file_path in OUTPUT_DIR.glob("*.jpg"):
                # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                file_mtime = file_path.stat().st_mtime
                if current_time - file_mtime > OUTPUT_FILE_RETENTION:
                    file_path.unlink()
                    deleted_count += 1
                    logger.info(f"ğŸ—‘ï¸  åˆ é™¤è¿‡æœŸæ–‡ä»¶: {file_path.name}")

            if deleted_count > 0:
                logger.info(f"âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {deleted_count} ä¸ªè¿‡æœŸæ–‡ä»¶")

        except Exception as e:
            logger.error(f"âŒ æ¸…ç†æ–‡ä»¶å¤±è´¥: {e}")


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨äº‹ä»¶"""
    logger.info("ğŸš€ æ­£åœ¨å¯åŠ¨ DeepSeek-OCR API æœåŠ¡...")
    logger.info(f"âš™ï¸  é…ç½®: LAZY_LOAD={LAZY_LOAD}, IDLE_TIMEOUT={IDLE_TIMEOUT}s ({IDLE_TIMEOUT/60:.1f}åˆ†é’Ÿ)")
    logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR.absolute()}")
    logger.info(f"ğŸ—‘ï¸  æ–‡ä»¶ä¿ç•™æ—¶é—´: {OUTPUT_FILE_RETENTION}s ({OUTPUT_FILE_RETENTION/3600:.1f}å°æ—¶)")
    logger.info(f"ğŸŒ API åŸºç¡€ URL: {API_BASE_URL}")

    if LAZY_LOAD:
        logger.info("ğŸ’¤ æŒ‰éœ€åŠ è½½æ¨¡å¼ï¼šæ¨¡å‹å°†åœ¨é¦–æ¬¡è¯·æ±‚æ—¶åŠ è½½")
        # å¯åŠ¨ç©ºé—²ç›‘æ§ä»»åŠ¡
        asyncio.create_task(idle_monitor())
    else:
        logger.info("ğŸ”¥ é¢„åŠ è½½æ¨¡å¼ï¼šç«‹å³åŠ è½½æ¨¡å‹")
        load_model()

    # å¯åŠ¨æ–‡ä»¶æ¸…ç†ä»»åŠ¡
    asyncio.create_task(cleanup_old_files())

    logger.info("âœ… æœåŠ¡å¯åŠ¨å®Œæˆï¼")


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "service": "DeepSeek-OCR API",
        "version": "1.0.0",
        "status": "running",
        "model_loaded": MODEL_LOADED,
        "device": DEVICE
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ï¼ˆä¸è§¦å‘æ¨¡å‹åŠ è½½ï¼‰"""
    health_info = {
        "status": "healthy",
        "model_loaded": MODEL_LOADED,
        "device": DEVICE,
        "gpu_available": torch.cuda.is_available(),
        "lazy_load": LAZY_LOAD,
        "idle_timeout": IDLE_TIMEOUT,
        "max_concurrent_requests": MAX_CONCURRENT_REQUESTS,
        "active_requests": active_requests,
        "max_file_size_mb": MAX_FILE_SIZE / 1024 / 1024,
        "timestamp": datetime.now().isoformat()
    }

    # å¦‚æœæ¨¡å‹å·²åŠ è½½ï¼Œæ˜¾ç¤ºç©ºé—²æ—¶é—´
    if MODEL_LOADED and last_request_time:
        idle_time = (datetime.now() - last_request_time).total_seconds()
        health_info["idle_time_seconds"] = idle_time
        health_info["idle_time_minutes"] = idle_time / 60

    # æ˜¾ç¤º GPU å†…å­˜ä½¿ç”¨
    if torch.cuda.is_available():
        health_info["gpu_memory_allocated_gb"] = torch.cuda.memory_allocated() / 1024**3
        health_info["gpu_memory_reserved_gb"] = torch.cuda.memory_reserved() / 1024**3

    return health_info


@app.get("/outputs/{filename}")
async def download_output(filename: str):
    """
    ä¸‹è½½ç”Ÿæˆçš„è¾“å‡ºæ–‡ä»¶

    æ”¯æŒè¿œç¨‹è®¿é—®ï¼Œå‰ç«¯å¯ä»¥é€šè¿‡æ­¤ç«¯ç‚¹è·å–ç”Ÿæˆçš„å›¾ç‰‡

    Args:
        filename: æ–‡ä»¶åï¼ˆä¸åŒ…å«è·¯å¾„ï¼‰

    Returns:
        FileResponse: å›¾ç‰‡æ–‡ä»¶

    Raises:
        HTTPException: 404 - æ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„éæ³•
    """
    # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢è·¯å¾„éå†æ”»å‡»
    if ".." in filename or "/" in filename or "\\" in filename:
        raise HTTPException(status_code=400, detail="éæ³•çš„æ–‡ä»¶å")

    file_path = OUTPUT_DIR / filename

    if not file_path.is_file():
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

    # ç¡®ä¿æ–‡ä»¶åœ¨ OUTPUT_DIR ç›®å½•å†…
    if not str(file_path.resolve()).startswith(str(OUTPUT_DIR.resolve())):
        raise HTTPException(status_code=403, detail="ç¦æ­¢è®¿é—®")

    return FileResponse(
        path=file_path,
        media_type="image/jpeg",
        filename=filename,
        headers={
            "Cache-Control": "public, max-age=3600",  # ç¼“å­˜ 1 å°æ—¶
            "Access-Control-Allow-Origin": "*"  # å…è®¸è·¨åŸŸè®¿é—®
        }
    )


@app.post("/ocr/image", response_model=OCRResponse)
async def ocr_image(
    file: UploadFile = File(...),
    prompt: Optional[str] = Form("<image>\n<|grounding|>Convert the document to markdown."),
    base_size: Optional[int] = Form(1024),
    image_size: Optional[int] = Form(640),
    crop_mode: Optional[bool] = Form(True),
    save_results: Optional[bool] = Form(False),
    test_compress: Optional[bool] = Form(False),
    draw_boxes: Optional[bool] = Form(False),  # å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨ /ocr/image/boxes
    extract_images: Optional[bool] = Form(False)  # å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨ /ocr/image/extract
):
    """
    å¯¹ä¸Šä¼ çš„å›¾ç‰‡æˆ– PDF è¿›è¡Œ OCR è¯†åˆ«ï¼ˆçº¯æ–‡æœ¬ç‰ˆï¼‰

    å‚æ•°:
    - file: å›¾ç‰‡æ–‡ä»¶æˆ– PDF æ–‡ä»¶
      - å›¾ç‰‡æ”¯æŒ: jpg, png, jpeg, bmp, gif, tiff, webp ç­‰æ ¼å¼
      - PDF æ”¯æŒ: è‡ªåŠ¨è¯†åˆ«å¹¶å¤„ç†æ‰€æœ‰é¡µé¢
    - prompt: OCR æç¤ºè¯
    - base_size: åŸºç¡€å°ºå¯¸
    - image_size: å›¾ç‰‡å°ºå¯¸
    - crop_mode: æ˜¯å¦è£å‰ªæ¨¡å¼
    - save_results: æ˜¯å¦ä¿å­˜ç»“æœ
    - test_compress: æ˜¯å¦æµ‹è¯•å‹ç¼©

    æ³¨æ„:
    - draw_boxes å’Œ extract_images å‚æ•°å·²åºŸå¼ƒï¼Œå°†è¢«å¿½ç•¥
    - å¦‚éœ€ç”»æ¡†åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨ /ocr/image/boxes
    - å¦‚éœ€æå–å›¾ç‰‡åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨ /ocr/image/extract
    - PDF æ–‡ä»¶ä¼šè‡ªåŠ¨å¤„ç†æ‰€æœ‰é¡µé¢ï¼Œè¿”å›åˆå¹¶çš„æ–‡æœ¬ç»“æœ
    """
    global last_request_time, active_requests

    # ä½¿ç”¨å¹¶å‘æ§åˆ¶ä¿¡å·é‡
    async with request_semaphore:
        # æ›´æ–°æ´»è·ƒè¯·æ±‚è®¡æ•°
        with active_requests_lock:
            active_requests += 1
            current_active = active_requests

        logger.info(f"ğŸ“¥ æ”¶åˆ° OCR è¯·æ±‚ï¼Œå½“å‰æ´»è·ƒè¯·æ±‚æ•°: {current_active}/{MAX_CONCURRENT_REQUESTS}")

        try:
            # æŒ‰éœ€åŠ è½½æ¨¡å‹
            if not MODEL_LOADED:
                logger.info("ğŸ”¥ æ£€æµ‹åˆ°è¯·æ±‚ï¼Œå¼€å§‹åŠ è½½æ¨¡å‹...")
                load_model()

            start_time = datetime.now()
            temp_file = None

            try:
                # è¯»å–æ–‡ä»¶å†…å®¹
                content = await file.read()

                # æ£€æµ‹æ–‡ä»¶ç±»å‹ï¼ˆæ”¯æŒå›¾ç‰‡å’Œ PDFï¼‰
                is_pdf_file = is_pdf(content)

                if not is_pdf_file:
                    # éªŒè¯å›¾ç‰‡æ–‡ä»¶ç±»å‹
                    if file.content_type and not file.content_type.startswith('image/'):
                        raise HTTPException(status_code=400, detail="åªæ”¯æŒå›¾ç‰‡æˆ– PDF æ–‡ä»¶")

                    # å¦‚æœæ²¡æœ‰ content_typeï¼Œé€šè¿‡æ–‡ä»¶æ‰©å±•åéªŒè¯
                    if not file.content_type:
                        allowed_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp'}
                        filename = file.filename or "image.jpg"
                        file_ext = Path(filename).suffix.lower()
                        if file_ext not in allowed_extensions:
                            raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}")

                # æ£€æŸ¥æ–‡ä»¶å¤§å°
                file_size = len(content)
                if file_size > MAX_FILE_SIZE:
                    raise HTTPException(
                        status_code=400,
                        detail=f"æ–‡ä»¶å¤ªå¤§: {file_size / 1024 / 1024:.2f}MBï¼Œæœ€å¤§å…è®¸: {MAX_FILE_SIZE / 1024 / 1024:.2f}MB"
                    )

                filename = file.filename or "image.jpg"

                # å¤„ç† PDF æˆ–å›¾ç‰‡
                if is_pdf_file:
                    logger.info(f"ğŸ“„ æ£€æµ‹åˆ° PDF æ–‡ä»¶: {filename}, å¤§å°: {file_size / 1024:.2f}KB")

                    # å°† PDF è½¬æ¢ä¸ºå›¾ç‰‡åˆ—è¡¨
                    images = pdf_to_images(content)
                    total_pages = len(images)
                    logger.info(f"ğŸ“„ PDF å…± {total_pages} é¡µ")

                    # å¯¹æ¯ä¸€é¡µè¿›è¡Œ OCR
                    all_results = []
                    for page_num, img in enumerate(images, 1):
                        logger.info(f"ğŸ“ å¤„ç†ç¬¬ {page_num}/{total_pages} é¡µ...")

                        # ä¿å­˜ä¸´æ—¶å›¾ç‰‡æ–‡ä»¶
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as tmp:
                            img.save(tmp.name, format='PNG')
                            temp_file = tmp.name

                        # æ‰§è¡Œ OCR
                        if save_results:
                            output_path = str(OUTPUT_DIR)
                        else:
                            import tempfile as tmp_module
                            temp_output_dir = tmp_module.mkdtemp(prefix="deepseek_ocr_")
                            output_path = temp_output_dir

                        page_result = model.infer(
                            tokenizer,
                            prompt=prompt,
                            image_file=temp_file,
                            output_path=output_path,
                            base_size=base_size,
                            image_size=image_size,
                            crop_mode=crop_mode,
                            save_results=save_results,
                            test_compress=test_compress,
                            eval_mode=True
                        )

                        all_results.append(f"# ç¬¬ {page_num} é¡µ\n\n{page_result}")

                        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        try:
                            os.unlink(temp_file)
                        except:
                            pass

                    # åˆå¹¶æ‰€æœ‰é¡µçš„ç»“æœ
                    result = "\n\n---\n\n".join(all_results)
                    temp_file = None  # å·²ç»æ¸…ç†è¿‡äº†

                else:
                    # å¤„ç†å›¾ç‰‡æ–‡ä»¶
                    suffix = Path(filename).suffix or ".jpg"
                    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                        tmp.write(content)
                        temp_file = tmp.name

                    logger.info(f"ğŸ–¼ï¸  å¤„ç†å›¾ç‰‡: {filename}, å¤§å°: {file_size / 1024:.2f}KB")
                    logger.info(f"Prompt: {prompt}")
                    logger.info(f"eval_mode: True, save_results: {save_results}")

                    # æ‰§è¡Œ OCR
                    if save_results:
                        output_path = str(OUTPUT_DIR)
                    else:
                        import tempfile as tmp_module
                        temp_output_dir = tmp_module.mkdtemp(prefix="deepseek_ocr_")
                        output_path = temp_output_dir

                    result = model.infer(
                        tokenizer,
                        prompt=prompt,
                        image_file=temp_file,
                        output_path=output_path,
                        base_size=base_size,
                        image_size=image_size,
                        crop_mode=crop_mode,
                        save_results=save_results,
                        test_compress=test_compress,
                        eval_mode=True
                    )

                # æ›´æ–°æœ€åè¯·æ±‚æ—¶é—´
                last_request_time = datetime.now()

                processing_time = (datetime.now() - start_time).total_seconds()

                logger.info(f"âœ… OCR å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}s")

                # æ¸…ç† GPU ç¼“å­˜
                if DEVICE == "cuda":
                    torch.cuda.empty_cache()

                # è¿”å›çº¯æ–‡æœ¬ç»“æœï¼ˆå¿½ç•¥ draw_boxes å’Œ extract_images å‚æ•°ï¼‰
                metadata = {
                    "filename": file.filename,
                    "file_size": file_size,
                    "base_size": base_size,
                    "image_size": image_size,
                    "crop_mode": crop_mode,
                }

                # å¦‚æœæ˜¯ PDFï¼Œæ·»åŠ é¡µæ•°ä¿¡æ¯
                if is_pdf_file:
                    metadata["file_type"] = "pdf"
                    metadata["total_pages"] = total_pages
                else:
                    metadata["file_type"] = "image"

                return OCRResponse(
                    success=True,
                    text=result,
                    processing_time=processing_time,
                    metadata=metadata,
                    image_with_boxes_url=None,
                    extracted_images_urls=None
                )

            except torch.cuda.OutOfMemoryError as e:
                # GPU å†…å­˜æº¢å‡ºé”™è¯¯
                logger.error(f"âŒ GPU å†…å­˜æº¢å‡º: {str(e)}")
                logger.info("ğŸ§¹ æ­£åœ¨æ¸…ç† GPU ç¼“å­˜...")

                # å¼ºåˆ¶æ¸…ç† GPU ç¼“å­˜
                if DEVICE == "cuda":
                    torch.cuda.empty_cache()
                    torch.cuda.synchronize()
                    gc.collect()

                raise HTTPException(
                    status_code=503,
                    detail=f"GPU å†…å­˜ä¸è¶³ï¼Œè¯·ç¨åé‡è¯•ã€‚å½“å‰æœ‰ {current_active} ä¸ªå¹¶å‘è¯·æ±‚æ­£åœ¨å¤„ç†ã€‚"
                )

            except Exception as e:
                logger.error(f"âŒ OCR å¤„ç†å¤±è´¥: {str(e)}")
                raise HTTPException(status_code=500, detail=f"OCR å¤„ç†å¤±è´¥: {str(e)}")

            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if temp_file and os.path.exists(temp_file):
                    try:
                        os.unlink(temp_file)
                    except:
                        pass

        finally:
            # å‡å°‘æ´»è·ƒè¯·æ±‚è®¡æ•°
            with active_requests_lock:
                active_requests -= 1
            logger.info(f"ğŸ“¤ è¯·æ±‚å®Œæˆï¼Œå½“å‰æ´»è·ƒè¯·æ±‚æ•°: {active_requests}/{MAX_CONCURRENT_REQUESTS}")


@app.post("/ocr/image/boxes", response_model=OCRBoxesResponse)
async def ocr_image_boxes(
    file: UploadFile = File(...),
    prompt: Optional[str] = Form("<image>\n<|grounding|>Convert the document to markdown."),
    base_size: Optional[int] = Form(1024),
    image_size: Optional[int] = Form(640),
    crop_mode: Optional[bool] = Form(True),
    save_results: Optional[bool] = Form(False),
    test_compress: Optional[bool] = Form(False),
    include_text: Optional[bool] = Form(True)  # æ˜¯å¦è¿”å›å®Œæ•´æ–‡æœ¬
):
    """
    å¯¹ä¸Šä¼ çš„å›¾ç‰‡æˆ– PDF è¿›è¡Œ OCR è¯†åˆ«å¹¶ç”»æ¡†

    å‚æ•°:
    - file: å›¾ç‰‡æ–‡ä»¶æˆ– PDF æ–‡ä»¶
    - prompt: OCR æç¤ºè¯
    - base_size: åŸºç¡€å°ºå¯¸
    - image_size: å›¾ç‰‡å°ºå¯¸
    - crop_mode: æ˜¯å¦è£å‰ªæ¨¡å¼
    - save_results: æ˜¯å¦ä¿å­˜ç»“æœ
    - test_compress: æ˜¯å¦æµ‹è¯•å‹ç¼©
    - include_text: æ˜¯å¦è¿”å›å®Œæ•´ OCR æ–‡æœ¬

    è¿”å›:
    - ç”»å¥½æ¡†çš„å›¾ç‰‡ URLï¼ˆPDF æ—¶è¿”å›ç¬¬ä¸€é¡µçš„ç”»æ¡†å›¾ç‰‡ï¼‰
    - æ‰€æœ‰è¾¹ç•Œæ¡†çš„ç»“æ„åŒ–ä¿¡æ¯ï¼ˆPDF æ—¶åŒ…å«æ‰€æœ‰é¡µï¼‰
    - å¯é€‰çš„å®Œæ•´ OCR æ–‡æœ¬ï¼ˆPDF æ—¶åŒ…å«æ‰€æœ‰é¡µï¼‰

    æ³¨æ„:
    - PDF æ–‡ä»¶ä¼šå¤„ç†æ‰€æœ‰é¡µé¢ï¼Œä¸ºæ¯ä¸€é¡µéƒ½ç”»æ¡†
    - è¿”å›çš„ image_with_boxes_url æ˜¯ç¬¬ä¸€é¡µçš„ç”»æ¡†å›¾ç‰‡
    - metadata ä¸­ä¼šåŒ…å« all_pages_urls å­—æ®µï¼ŒåŒ…å«æ‰€æœ‰é¡µçš„ç”»æ¡†å›¾ç‰‡ URL
    """
    global last_request_time, active_requests

    async with request_semaphore:
        with active_requests_lock:
            active_requests += 1
            current_active = active_requests

        logger.info(f"ğŸ“¥ æ”¶åˆ°ç”»æ¡†è¯·æ±‚ï¼Œå½“å‰æ´»è·ƒè¯·æ±‚æ•°: {current_active}/{MAX_CONCURRENT_REQUESTS}")

        try:
            if not MODEL_LOADED:
                logger.info("ğŸ”¥ æ£€æµ‹åˆ°è¯·æ±‚ï¼Œå¼€å§‹åŠ è½½æ¨¡å‹...")
                load_model()

            start_time = datetime.now()
            temp_file = None

            try:
                # è¯»å–æ–‡ä»¶å†…å®¹
                content = await file.read()
                file_size = len(content)

                # æ£€æµ‹æ–‡ä»¶ç±»å‹ï¼ˆæ”¯æŒå›¾ç‰‡å’Œ PDFï¼‰
                is_pdf_file = is_pdf(content)

                if not is_pdf_file:
                    # éªŒè¯å›¾ç‰‡æ–‡ä»¶ç±»å‹
                    if file.content_type and not file.content_type.startswith('image/'):
                        raise HTTPException(status_code=400, detail="åªæ”¯æŒå›¾ç‰‡æˆ– PDF æ–‡ä»¶")

                    if not file.content_type:
                        allowed_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp'}
                        filename = file.filename or "image.jpg"
                        file_ext = Path(filename).suffix.lower()
                        if file_ext not in allowed_extensions:
                            raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}")

                if file_size > MAX_FILE_SIZE:
                    raise HTTPException(
                        status_code=400,
                        detail=f"æ–‡ä»¶å¤ªå¤§: {file_size / 1024 / 1024:.2f}MBï¼Œæœ€å¤§å…è®¸: {MAX_FILE_SIZE / 1024 / 1024:.2f}MB"
                    )

                filename = file.filename or "image.jpg"

                # å¤„ç† PDF æˆ–å›¾ç‰‡
                all_boxes = []
                all_text_parts = []
                all_pages_urls = []
                total_pages = 1

                if is_pdf_file:
                    logger.info(f"ğŸ“„ æ£€æµ‹åˆ° PDF æ–‡ä»¶: {filename}, å¤§å°: {file_size / 1024:.2f}KB")

                    # å°† PDF è½¬æ¢ä¸ºå›¾ç‰‡åˆ—è¡¨
                    images = pdf_to_images(content)
                    total_pages = len(images)
                    logger.info(f"ğŸ“„ PDF å…± {total_pages} é¡µ")

                    # å¯¹æ¯ä¸€é¡µè¿›è¡Œ OCR å’Œç”»æ¡†
                    for page_num, img in enumerate(images, 1):
                        logger.info(f"ğŸ“ å¤„ç†ç¬¬ {page_num}/{total_pages} é¡µ...")

                        # ä¿å­˜ä¸´æ—¶å›¾ç‰‡æ–‡ä»¶
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as tmp:
                            img.save(tmp.name, format='PNG')
                            temp_file = tmp.name

                        # æ‰§è¡Œ OCR
                        if save_results:
                            output_path = str(OUTPUT_DIR)
                        else:
                            import tempfile as tmp_module
                            temp_output_dir = tmp_module.mkdtemp(prefix="deepseek_ocr_")
                            output_path = temp_output_dir

                        page_result = model.infer(
                            tokenizer,
                            prompt=prompt,
                            image_file=temp_file,
                            output_path=output_path,
                            base_size=base_size,
                            image_size=image_size,
                            crop_mode=crop_mode,
                            save_results=save_results,
                            test_compress=test_compress,
                            eval_mode=True
                        )

                        all_text_parts.append(f"# ç¬¬ {page_num} é¡µ\n\n{page_result}")

                        # è§£æè¾¹ç•Œæ¡†
                        image_width, image_height = img.size
                        page_boxes = _parse_boxes_from_text(page_result, image_width, image_height)
                        all_boxes.extend(page_boxes)

                        # ç”»æ¡†
                        import uuid
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        unique_id = str(uuid.uuid4())[:8]
                        filename_prefix = f"{Path(filename).stem}_page{page_num}_{timestamp}_{unique_id}"

                        page_boxes_url, _ = draw_bounding_boxes(
                            img,
                            page_result,
                            extract_images=False,
                            save_to_disk=True,
                            filename_prefix=filename_prefix
                        )

                        if page_boxes_url:
                            page_boxes_url = f"{API_BASE_URL}{page_boxes_url}"
                            all_pages_urls.append(page_boxes_url)
                            logger.info(f"âœ… ç¬¬ {page_num} é¡µè¾¹ç•Œæ¡†ç»˜åˆ¶å®Œæˆ: {page_boxes_url}")

                        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        try:
                            os.unlink(temp_file)
                        except:
                            pass

                    result = "\n\n---\n\n".join(all_text_parts)
                    boxes = all_boxes
                    image_with_boxes_url = all_pages_urls[0] if all_pages_urls else None
                    temp_file = None  # å·²ç»æ¸…ç†è¿‡äº†

                else:
                    # å¤„ç†å›¾ç‰‡æ–‡ä»¶
                    suffix = Path(filename).suffix or ".jpg"
                    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                        tmp.write(content)
                        temp_file = tmp.name

                    logger.info(f"ğŸ–¼ï¸  å¤„ç†å›¾ç‰‡: {filename}, å¤§å°: {file_size / 1024:.2f}KB")

                    # æ‰§è¡Œ OCR
                    if save_results:
                        output_path = str(OUTPUT_DIR)
                    else:
                        import tempfile as tmp_module
                        temp_output_dir = tmp_module.mkdtemp(prefix="deepseek_ocr_")
                        output_path = temp_output_dir

                    result = model.infer(
                        tokenizer,
                        prompt=prompt,
                        image_file=temp_file,
                        output_path=output_path,
                        base_size=base_size,
                        image_size=image_size,
                        crop_mode=crop_mode,
                        save_results=save_results,
                        test_compress=test_compress,
                        eval_mode=True
                    )

                    # è§£æè¾¹ç•Œæ¡†
                    original_image = Image.open(temp_file).convert('RGB')
                    image_width, image_height = original_image.size
                    boxes = _parse_boxes_from_text(result, image_width, image_height)

                    # ç”»æ¡†
                    import uuid
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    unique_id = str(uuid.uuid4())[:8]
                    filename_prefix = f"{Path(filename).stem}_{timestamp}_{unique_id}"

                    image_with_boxes_url, _ = draw_bounding_boxes(
                        original_image,
                        result,
                        extract_images=False,
                        save_to_disk=True,
                        filename_prefix=filename_prefix
                    )

                # æ›´æ–°æœ€åè¯·æ±‚æ—¶é—´å’Œè®¡ç®—å¤„ç†æ—¶é—´
                last_request_time = datetime.now()
                processing_time = (datetime.now() - start_time).total_seconds()

                logger.info(f"âœ… ç”»æ¡†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}s")

                # è½¬æ¢ä¸ºå®Œæ•´ URLï¼ˆå›¾ç‰‡æ–‡ä»¶ï¼‰
                if not is_pdf_file and image_with_boxes_url:
                    image_with_boxes_url = f"{API_BASE_URL}{image_with_boxes_url}"
                    logger.info(f"âœ… è¾¹ç•Œæ¡†ç»˜åˆ¶å®Œæˆ: {image_with_boxes_url}")

                # ç”Ÿæˆ labels_summary
                labels_summary = sorted(list(set(box.label_type for box in boxes)))

                # æ¸…ç† GPU ç¼“å­˜
                if DEVICE == "cuda":
                    torch.cuda.empty_cache()

                # æ„å»º metadata
                metadata = {
                    "filename": filename,
                    "file_size": file_size,
                    "base_size": base_size,
                    "image_size": image_size,
                    "crop_mode": crop_mode,
                    "boxes_count": len(boxes)
                }

                # å¦‚æœæ˜¯ PDFï¼Œæ·»åŠ é¡µæ•°ä¿¡æ¯å’Œæ‰€æœ‰é¡µçš„ URL
                if is_pdf_file:
                    metadata["file_type"] = "pdf"
                    metadata["total_pages"] = total_pages
                    metadata["all_pages_urls"] = all_pages_urls
                else:
                    metadata["file_type"] = "image"

                return OCRBoxesResponse(
                    success=True,
                    image_with_boxes_url=image_with_boxes_url or "",
                    boxes=boxes,
                    text=result if include_text else None,
                    question=prompt,
                    labels_summary=labels_summary,
                    processing_time=processing_time,
                    metadata=metadata
                )

            except Exception as e:
                logger.error(f"âŒ ç”»æ¡†å¤„ç†å¤±è´¥: {str(e)}")
                raise HTTPException(status_code=500, detail=f"ç”»æ¡†å¤„ç†å¤±è´¥: {str(e)}")

            finally:
                if temp_file and os.path.exists(temp_file):
                    try:
                        os.unlink(temp_file)
                    except:
                        pass

        finally:
            with active_requests_lock:
                active_requests -= 1
            logger.info(f"ğŸ“¤ è¯·æ±‚å®Œæˆï¼Œå½“å‰æ´»è·ƒè¯·æ±‚æ•°: {active_requests}/{MAX_CONCURRENT_REQUESTS}")


@app.post("/ocr/image/extract", response_model=OCRExtractResponse)
async def ocr_image_extract(
    file: UploadFile = File(...),
    prompt: Optional[str] = Form("<image>\n<|grounding|>Convert the document to markdown."),
    base_size: Optional[int] = Form(1024),
    image_size: Optional[int] = Form(640),
    crop_mode: Optional[bool] = Form(True),
    save_results: Optional[bool] = Form(False),
    test_compress: Optional[bool] = Form(False),
    include_text: Optional[bool] = Form(True),  # æ˜¯å¦è¿”å›å®Œæ•´æ–‡æœ¬
    include_boxes: Optional[bool] = Form(False)  # æ˜¯å¦è¿”å›è¾¹ç•Œæ¡†ä¿¡æ¯
):
    """
    å¯¹ä¸Šä¼ çš„å›¾ç‰‡æˆ– PDF è¿›è¡Œ OCR è¯†åˆ«å¹¶æå–å›¾ç‰‡åŒºåŸŸ

    å‚æ•°:
    - file: å›¾ç‰‡æ–‡ä»¶æˆ– PDF æ–‡ä»¶
    - prompt: OCR æç¤ºè¯
    - base_size: åŸºç¡€å°ºå¯¸
    - image_size: å›¾ç‰‡å°ºå¯¸
    - crop_mode: æ˜¯å¦è£å‰ªæ¨¡å¼
    - save_results: æ˜¯å¦ä¿å­˜ç»“æœ
    - test_compress: æ˜¯å¦æµ‹è¯•å‹ç¼©
    - include_text: æ˜¯å¦è¿”å›å®Œæ•´ OCR æ–‡æœ¬
    - include_boxes: æ˜¯å¦è¿”å›è¾¹ç•Œæ¡†ä¿¡æ¯

    è¿”å›:
    - æå–çš„å›¾ç‰‡åŒºåŸŸåˆ—è¡¨ï¼ˆæ¯ä¸ªåŒºåŸŸåŒ…å«å­å›¾ URLã€è¾¹ç•Œæ¡†ã€å¯¹åº”æ–‡å­—ï¼‰
    - å¯é€‰çš„å®Œæ•´ OCR æ–‡æœ¬

    æ³¨æ„:
    - PDF æ–‡ä»¶ä¼šå¤„ç†æ‰€æœ‰é¡µé¢ï¼Œæå–æ‰€æœ‰é¡µé¢ä¸­çš„å›¾ç‰‡åŒºåŸŸ
    """
    global last_request_time, active_requests

    async with request_semaphore:
        with active_requests_lock:
            active_requests += 1
            current_active = active_requests

        logger.info(f"ğŸ“¥ æ”¶åˆ°æå–è¯·æ±‚ï¼Œå½“å‰æ´»è·ƒè¯·æ±‚æ•°: {current_active}/{MAX_CONCURRENT_REQUESTS}")

        try:
            if not MODEL_LOADED:
                logger.info("ğŸ”¥ æ£€æµ‹åˆ°è¯·æ±‚ï¼Œå¼€å§‹åŠ è½½æ¨¡å‹...")
                load_model()

            start_time = datetime.now()
            temp_file = None

            try:
                # è¯»å–æ–‡ä»¶å†…å®¹
                content = await file.read()
                file_size = len(content)

                # æ£€æµ‹æ–‡ä»¶ç±»å‹ï¼ˆæ”¯æŒå›¾ç‰‡å’Œ PDFï¼‰
                is_pdf_file = is_pdf(content)

                if not is_pdf_file:
                    # éªŒè¯å›¾ç‰‡æ–‡ä»¶ç±»å‹
                    if file.content_type and not file.content_type.startswith('image/'):
                        raise HTTPException(status_code=400, detail="åªæ”¯æŒå›¾ç‰‡æˆ– PDF æ–‡ä»¶")

                    if not file.content_type:
                        allowed_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp'}
                        filename = file.filename or "image.jpg"
                        file_ext = Path(filename).suffix.lower()
                        if file_ext not in allowed_extensions:
                            raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}")

                if file_size > MAX_FILE_SIZE:
                    raise HTTPException(
                        status_code=400,
                        detail=f"æ–‡ä»¶å¤ªå¤§: {file_size / 1024 / 1024:.2f}MBï¼Œæœ€å¤§å…è®¸: {MAX_FILE_SIZE / 1024 / 1024:.2f}MB"
                    )

                filename = file.filename or "image.jpg"

                # å¤„ç† PDF æˆ–å›¾ç‰‡
                all_regions = []
                all_text_parts = []
                total_pages = 1

                if is_pdf_file:
                    logger.info(f"ğŸ“„ æ£€æµ‹åˆ° PDF æ–‡ä»¶: {filename}, å¤§å°: {file_size / 1024:.2f}KB")

                    # å°† PDF è½¬æ¢ä¸ºå›¾ç‰‡åˆ—è¡¨
                    images = pdf_to_images(content)
                    total_pages = len(images)
                    logger.info(f"ğŸ“„ PDF å…± {total_pages} é¡µ")

                    # å¯¹æ¯ä¸€é¡µè¿›è¡Œ OCR å’Œæå–
                    for page_num, img in enumerate(images, 1):
                        logger.info(f"ğŸ“ å¤„ç†ç¬¬ {page_num}/{total_pages} é¡µ...")

                        # ä¿å­˜ä¸´æ—¶å›¾ç‰‡æ–‡ä»¶
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as tmp:
                            img.save(tmp.name, format='PNG')
                            temp_file = tmp.name

                        # æ‰§è¡Œ OCR
                        if save_results:
                            output_path = str(OUTPUT_DIR)
                        else:
                            import tempfile as tmp_module
                            temp_output_dir = tmp_module.mkdtemp(prefix="deepseek_ocr_")
                            output_path = temp_output_dir

                        page_result = model.infer(
                            tokenizer,
                            prompt=prompt,
                            image_file=temp_file,
                            output_path=output_path,
                            base_size=base_size,
                            image_size=image_size,
                            crop_mode=crop_mode,
                            save_results=save_results,
                            test_compress=test_compress,
                            eval_mode=True
                        )

                        all_text_parts.append(f"# ç¬¬ {page_num} é¡µ\n\n{page_result}")

                        # è§£æè¾¹ç•Œæ¡†å¹¶æå–å›¾ç‰‡åŒºåŸŸ
                        image_width, image_height = img.size
                        boxes = _parse_boxes_from_text(page_result, image_width, image_height)

                        # æå–å›¾ç‰‡åŒºåŸŸ
                        import uuid
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        unique_id = str(uuid.uuid4())[:8]
                        filename_prefix = f"{Path(filename).stem}_page{page_num}_{timestamp}_{unique_id}"

                        for box in boxes:
                            if box.label_type == "image":
                                try:
                                    cropped = img.crop((box.x1_px, box.y1_px, box.x2_px, box.y2_px))
                                    extracted_filename = f"{filename_prefix}_extracted_{len(all_regions)+1}.jpg"
                                    extracted_path = OUTPUT_DIR / extracted_filename
                                    cropped.save(extracted_path, 'JPEG', quality=95)

                                    image_url = f"{API_BASE_URL}/outputs/{extracted_filename}"
                                    region_text = _extract_region_text(page_result, len([r for r in all_regions if r.label_type == "image"]))

                                    region = Region(
                                        id=f"{box.id}_page{page_num}",
                                        label_type=box.label_type,
                                        page_number=page_num,
                                        bbox=box if include_boxes else None,
                                        image_url=image_url,
                                        text=region_text
                                    )
                                    all_regions.append(region)
                                    logger.info(f"âœ… æå–å›¾ç‰‡åŒºåŸŸ: {extracted_filename}")
                                except Exception as e:
                                    logger.error(f"âŒ æå–å›¾ç‰‡åŒºåŸŸå¤±è´¥: {e}")
                                    continue

                        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        try:
                            os.unlink(temp_file)
                        except:
                            pass

                    result = "\n\n---\n\n".join(all_text_parts)
                    regions = all_regions
                    temp_file = None  # å·²ç»æ¸…ç†è¿‡äº†

                else:
                    # å¤„ç†å›¾ç‰‡æ–‡ä»¶
                    suffix = Path(filename).suffix or ".jpg"
                    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                        tmp.write(content)
                        temp_file = tmp.name

                    logger.info(f"ğŸ–¼ï¸  å¤„ç†å›¾ç‰‡: {filename}, å¤§å°: {file_size / 1024:.2f}KB")

                    # æ‰§è¡Œ OCR
                    if save_results:
                        output_path = str(OUTPUT_DIR)
                    else:
                        import tempfile as tmp_module
                        temp_output_dir = tmp_module.mkdtemp(prefix="deepseek_ocr_")
                        output_path = temp_output_dir

                    result = model.infer(
                        tokenizer,
                        prompt=prompt,
                        image_file=temp_file,
                        output_path=output_path,
                        base_size=base_size,
                        image_size=image_size,
                        crop_mode=crop_mode,
                        save_results=save_results,
                        test_compress=test_compress,
                        eval_mode=True
                    )

                    # è§£æè¾¹ç•Œæ¡†
                    original_image = Image.open(temp_file).convert('RGB')
                    image_width, image_height = original_image.size
                    boxes = _parse_boxes_from_text(result, image_width, image_height)

                    # æå–å›¾ç‰‡åŒºåŸŸ
                    import uuid
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    unique_id = str(uuid.uuid4())[:8]
                    filename_prefix = f"{Path(filename).stem}_{timestamp}_{unique_id}"

                    regions = []
                    region_idx = 0

                    for box in boxes:
                        # åªæå– label_type ä¸º "image" çš„åŒºåŸŸ
                        if box.label_type == "image":
                            try:
                                # è£å‰ªå›¾ç‰‡
                                cropped = original_image.crop((box.x1_px, box.y1_px, box.x2_px, box.y2_px))

                                # ä¿å­˜è£å‰ªçš„å›¾ç‰‡
                                extracted_filename = f"{filename_prefix}_extracted_{region_idx+1}_{timestamp}_{unique_id}.jpg"
                                extracted_path = OUTPUT_DIR / extracted_filename
                                cropped.save(extracted_path, 'JPEG', quality=95)

                                image_url = f"{API_BASE_URL}/outputs/{extracted_filename}"

                                # æå–è¯¥åŒºåŸŸçš„æ–‡å­—
                                region_text = _extract_region_text(result, region_idx)

                                region = Region(
                                    id=box.id,
                                    label_type=box.label_type,
                                    bbox=box if include_boxes else None,
                                    image_url=image_url,
                                    text=region_text
                                )
                                regions.append(region)
                                region_idx += 1

                                logger.info(f"âœ… æå–å›¾ç‰‡åŒºåŸŸ: {extracted_filename}")
                            except Exception as e:
                                logger.error(f"âŒ æå–å›¾ç‰‡åŒºåŸŸå¤±è´¥: {e}")
                                continue

                    logger.info(f"âœ… å…±æå–äº† {len(regions)} ä¸ªå›¾ç‰‡åŒºåŸŸ")

                # æ›´æ–°æœ€åè¯·æ±‚æ—¶é—´å’Œè®¡ç®—å¤„ç†æ—¶é—´
                last_request_time = datetime.now()
                processing_time = (datetime.now() - start_time).total_seconds()

                logger.info(f"âœ… æå–å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}sï¼Œå…±æå– {len(regions)} ä¸ªåŒºåŸŸ")

                # æ¸…ç† GPU ç¼“å­˜
                if DEVICE == "cuda":
                    torch.cuda.empty_cache()

                # æ„å»º metadata
                metadata = {
                    "filename": filename,
                    "file_size": file_size,
                    "base_size": base_size,
                    "image_size": image_size,
                    "crop_mode": crop_mode,
                    "regions_count": len(regions)
                }

                # å¦‚æœæ˜¯ PDFï¼Œæ·»åŠ é¡µæ•°ä¿¡æ¯
                if is_pdf_file:
                    metadata["file_type"] = "pdf"
                    metadata["total_pages"] = total_pages
                else:
                    metadata["file_type"] = "image"

                return OCRExtractResponse(
                    success=True,
                    text=result if include_text else None,
                    regions=regions,
                    question=prompt,
                    processing_time=processing_time,
                    metadata=metadata
                )

            except Exception as e:
                logger.error(f"âŒ æå–å¤„ç†å¤±è´¥: {str(e)}")
                raise HTTPException(status_code=500, detail=f"æå–å¤„ç†å¤±è´¥: {str(e)}")

            finally:
                if temp_file and os.path.exists(temp_file):
                    try:
                        os.unlink(temp_file)
                    except:
                        pass

        finally:
            with active_requests_lock:
                active_requests -= 1
            logger.info(f"ğŸ“¤ è¯·æ±‚å®Œæˆï¼Œå½“å‰æ´»è·ƒè¯·æ±‚æ•°: {active_requests}/{MAX_CONCURRENT_REQUESTS}")


@app.post("/ocr/batch", response_model=List[OCRResponse])
async def ocr_batch(
    files: List[UploadFile] = File(...),
    prompt: Optional[str] = Form("<image>\n<|grounding|>Convert the document to markdown."),
    base_size: Optional[int] = Form(1024),
    image_size: Optional[int] = Form(640),
    crop_mode: Optional[bool] = Form(True)
):
    """
    æ‰¹é‡å¤„ç†å¤šä¸ªå›¾ç‰‡
    """
    global last_request_time

    # æŒ‰éœ€åŠ è½½æ¨¡å‹
    if not MODEL_LOADED:
        logger.info("ğŸ”¥ æ£€æµ‹åˆ°æ‰¹é‡è¯·æ±‚ï¼Œå¼€å§‹åŠ è½½æ¨¡å‹...")
        load_model()
    
    results = []
    
    for file in files:
        result = await ocr_image(
            file=file,
            prompt=prompt,
            base_size=base_size,
            image_size=image_size,
            crop_mode=crop_mode,
            save_results=False,
            test_compress=True
        )
        results.append(result)
    
    return results


@app.post("/ocr/base64", response_model=OCRResponse)
async def ocr_base64(
    image_base64: str = Form(...),
    prompt: Optional[str] = Form("<image>\n<|grounding|>Convert the document to markdown."),
    base_size: Optional[int] = Form(1024),
    image_size: Optional[int] = Form(640),
    crop_mode: Optional[bool] = Form(True)
):
    """
    å¯¹ Base64 ç¼–ç çš„å›¾ç‰‡è¿›è¡Œ OCR è¯†åˆ«
    """
    global last_request_time

    # æŒ‰éœ€åŠ è½½æ¨¡å‹
    if not MODEL_LOADED:
        logger.info("ğŸ”¥ æ£€æµ‹åˆ° Base64 è¯·æ±‚ï¼Œå¼€å§‹åŠ è½½æ¨¡å‹...")
        load_model()
    
    start_time = datetime.now()
    temp_file = None
    
    try:
        # è§£ç  Base64
        image_data = base64.b64decode(image_base64)
        
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp:
            tmp.write(image_data)
            temp_file = tmp.name
        
        # æ‰§è¡Œ OCR
        result = model.infer(
            tokenizer,
            prompt=prompt,
            image_file=temp_file,
            output_path=None,
            base_size=base_size,
            image_size=image_size,
            crop_mode=crop_mode,
            save_results=False,
            test_compress=True
        )

        # æ›´æ–°æœ€åè¯·æ±‚æ—¶é—´
        last_request_time = datetime.now()

        processing_time = (datetime.now() - start_time).total_seconds()
        
        return OCRResponse(
            success=True,
            text=result,
            processing_time=processing_time
        )
        
    except Exception as e:
        logger.error(f"OCR å¤„ç†å¤±è´¥: {str(e)}")
        return OCRResponse(
            success=False,
            error=str(e)
        )
    
    finally:
        if temp_file and os.path.exists(temp_file):
            try:
                os.unlink(temp_file)
            except:
                pass


@app.post("/admin/unload")
async def admin_unload():
    """æ‰‹åŠ¨å¸è½½æ¨¡å‹ï¼ˆç®¡ç†ç«¯ç‚¹ï¼‰"""
    if not MODEL_LOADED:
        return {"status": "info", "message": "æ¨¡å‹æœªåŠ è½½ï¼Œæ— éœ€å¸è½½"}

    unload_model()
    return {"status": "success", "message": "æ¨¡å‹å·²å¸è½½ï¼ŒGPU å†…å­˜å·²é‡Šæ”¾"}


@app.post("/admin/load")
async def admin_load():
    """æ‰‹åŠ¨åŠ è½½æ¨¡å‹ï¼ˆç®¡ç†ç«¯ç‚¹ï¼‰"""
    if MODEL_LOADED:
        return {"status": "info", "message": "æ¨¡å‹å·²åŠ è½½"}

    load_model()
    return {"status": "success", "message": "æ¨¡å‹å·²åŠ è½½"}


@app.get("/admin/status")
async def admin_status():
    """è·å–è¯¦ç»†çŠ¶æ€ä¿¡æ¯ï¼ˆç®¡ç†ç«¯ç‚¹ï¼‰"""
    status = {
        "model_loaded": MODEL_LOADED,
        "device": DEVICE,
        "lazy_load": LAZY_LOAD,
        "idle_timeout": IDLE_TIMEOUT,
        "idle_timeout_minutes": IDLE_TIMEOUT / 60,
    }

    if last_request_time:
        idle_time = (datetime.now() - last_request_time).total_seconds()
        status["last_request_time"] = last_request_time.isoformat()
        status["idle_time_seconds"] = idle_time
        status["idle_time_minutes"] = idle_time / 60
        status["will_unload_in_seconds"] = max(0, IDLE_TIMEOUT - idle_time)

    if torch.cuda.is_available():
        status["gpu_available"] = True
        status["gpu_name"] = torch.cuda.get_device_name(0)
        status["gpu_memory_allocated_gb"] = torch.cuda.memory_allocated() / 1024**3
        status["gpu_memory_reserved_gb"] = torch.cuda.memory_reserved() / 1024**3
        status["gpu_memory_total_gb"] = torch.cuda.get_device_properties(0).total_memory / 1024**3
    else:
        status["gpu_available"] = False

    return status


if __name__ == "__main__":
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8200,  # ä¿®æ”¹ä¸ºéä¸»æµç«¯å£é¿å…å†²çª
        reload=False,
        workers=1,
        timeout_keep_alive=300,  # ä¿æŒè¿æ¥ 5 åˆ†é’Ÿ
        timeout_graceful_shutdown=30,  # ä¼˜é›…å…³é—­è¶…æ—¶ 30 ç§’
        limit_concurrency=10,  # é™åˆ¶å¹¶å‘è¿æ¥æ•°
        backlog=2048  # å¢åŠ ç§¯å‹é˜Ÿåˆ—
    )

