# DeepSeek-OCR éƒ¨ç½²æ–‡æ¡£

## ğŸ“‹ ç›®å½•

- [ç³»ç»Ÿè¦æ±‚](#ç³»ç»Ÿè¦æ±‚)
- [æœ¬åœ°éƒ¨ç½²](#æœ¬åœ°éƒ¨ç½²)
- [Docker éƒ¨ç½²](#docker-éƒ¨ç½²)
- [API ä½¿ç”¨è¯´æ˜](#api-ä½¿ç”¨è¯´æ˜)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸ–¥ï¸ ç³»ç»Ÿè¦æ±‚

### ç¡¬ä»¶è¦æ±‚
- **GPU**: NVIDIA GPU (æ¨è 16GB+ æ˜¾å­˜)
- **å†…å­˜**: 32GB+ RAM (æ¨è 64GB)
- **å­˜å‚¨**: 50GB+ å¯ç”¨ç©ºé—´

### è½¯ä»¶è¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Windows 10/11, Linux (Ubuntu 20.04+)
- **CUDA**: 11.8+ (æ¨è 12.x)
- **Python**: 3.12.9
- **Docker**: 20.10+ (å¯é€‰ï¼Œç”¨äºå®¹å™¨åŒ–éƒ¨ç½²)
- **NVIDIA Container Toolkit**: ç”¨äº Docker GPU æ”¯æŒ

---

## ğŸš€ æœ¬åœ°éƒ¨ç½²

### æ–¹æ³• 1: ä½¿ç”¨è‡ªåŠ¨å®‰è£…è„šæœ¬ (Windows)

```powershell
# è¿è¡Œå®‰è£…è„šæœ¬
.\setup_env.ps1
```

### æ–¹æ³• 2: æ‰‹åŠ¨å®‰è£…

#### 1. åˆ›å»º Conda ç¯å¢ƒ

```bash
# åˆ›å»ºç¯å¢ƒ
conda create -n deepseek-ocr python=3.12.9 -y

# æ¿€æ´»ç¯å¢ƒ
conda activate deepseek-ocr
```

#### 2. å®‰è£…ä¾èµ–

```bash
# å®‰è£… PyTorch (CUDA 11.8)
pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu118

# å®‰è£…åŸºç¡€ä¾èµ–
pip install -r requirements.txt

# å®‰è£… flash-attention
pip install flash-attn==2.7.3 --no-build-isolation

# å®‰è£… API æœåŠ¡ä¾èµ–
pip install fastapi==0.109.0 uvicorn[standard]==0.27.0 python-multipart==0.0.6 aiofiles==23.2.1 requests
```

#### 3. å¯åŠ¨æœåŠ¡

```bash
# å¯åŠ¨ API æœåŠ¡
python api_server.py
```

æœåŠ¡å°†åœ¨ `http://localhost:8000` å¯åŠ¨

#### 4. æµ‹è¯•æœåŠ¡

```bash
# åœ¨æ–°ç»ˆç«¯ä¸­è¿è¡Œæµ‹è¯•
python test_api.py
```

---

## ğŸ³ Docker éƒ¨ç½²

### å‰ç½®è¦æ±‚

1. **å®‰è£… Docker Desktop** (Windows)
   - ä¸‹è½½: https://www.docker.com/products/docker-desktop

2. **å®‰è£… NVIDIA Container Toolkit**
   ```bash
   # Linux
   distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
   curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
   curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
   sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit
   sudo systemctl restart docker
   ```

### éƒ¨ç½²æ­¥éª¤

#### 1. æ„å»ºé•œåƒ

```bash
# ä½¿ç”¨ docker-compose æ„å»º
docker-compose build

# æˆ–ä½¿ç”¨ docker å‘½ä»¤
docker build -t deepseek-ocr:latest .
```

#### 2. å¯åŠ¨æœåŠ¡

```bash
# å¯åŠ¨æœåŠ¡ (åå°è¿è¡Œ)
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f
```

#### 3. åœæ­¢æœåŠ¡

```bash
# åœæ­¢æœåŠ¡
docker-compose down

# åœæ­¢å¹¶åˆ é™¤æ•°æ®å·
docker-compose down -v
```

#### 4. ç®¡ç†å®¹å™¨

```bash
# æŸ¥çœ‹å®¹å™¨çŠ¶æ€
docker-compose ps

# é‡å¯æœåŠ¡
docker-compose restart

# è¿›å…¥å®¹å™¨
docker-compose exec deepseek-ocr bash
```

---

## ğŸ“¡ API ä½¿ç”¨è¯´æ˜

### API æ–‡æ¡£

å¯åŠ¨æœåŠ¡åï¼Œè®¿é—®ä»¥ä¸‹åœ°å€æŸ¥çœ‹äº¤äº’å¼ API æ–‡æ¡£ï¼š
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

### ç«¯ç‚¹è¯´æ˜

#### 1. å¥åº·æ£€æŸ¥

```bash
GET /health
```

**å“åº”ç¤ºä¾‹:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "device": "cuda",
  "gpu_available": true,
  "timestamp": "2025-10-29T15:30:00"
}
```

#### 2. å›¾ç‰‡ OCR

```bash
POST /ocr/image
```

**å‚æ•°:**
- `file`: å›¾ç‰‡æ–‡ä»¶ (multipart/form-data)
- `prompt`: OCR æç¤ºè¯ (å¯é€‰)
- `base_size`: åŸºç¡€å°ºå¯¸ (é»˜è®¤: 1024)
- `image_size`: å›¾ç‰‡å°ºå¯¸ (é»˜è®¤: 640)
- `crop_mode`: è£å‰ªæ¨¡å¼ (é»˜è®¤: true)

**Python ç¤ºä¾‹:**
```python
import requests

url = "http://localhost:8000/ocr/image"
files = {'file': open('test.jpg', 'rb')}
data = {
    'prompt': '<image>\n<|grounding|>Convert the document to markdown.',
    'base_size': 1024,
    'image_size': 640,
    'crop_mode': True
}

response = requests.post(url, files=files, data=data)
result = response.json()
print(result['text'])
```

**cURL ç¤ºä¾‹:**
```bash
curl -X POST "http://localhost:8000/ocr/image" \
  -F "file=@test.jpg" \
  -F "prompt=<image>\n<|grounding|>Convert the document to markdown." \
  -F "base_size=1024" \
  -F "image_size=640" \
  -F "crop_mode=true"
```

#### 3. Base64 å›¾ç‰‡ OCR

```bash
POST /ocr/base64
```

**Python ç¤ºä¾‹:**
```python
import requests
import base64

with open('test.jpg', 'rb') as f:
    image_base64 = base64.b64encode(f.read()).decode('utf-8')

url = "http://localhost:8000/ocr/base64"
data = {
    'image_base64': image_base64,
    'prompt': '<image>\nFree OCR.'
}

response = requests.post(url, data=data)
result = response.json()
print(result['text'])
```

#### 4. æ‰¹é‡ OCR

```bash
POST /ocr/batch
```

**Python ç¤ºä¾‹:**
```python
import requests

url = "http://localhost:8000/ocr/batch"
files = [
    ('files', open('test1.jpg', 'rb')),
    ('files', open('test2.jpg', 'rb')),
    ('files', open('test3.jpg', 'rb'))
]
data = {'prompt': '<image>\n<|grounding|>Convert the document to markdown.'}

response = requests.post(url, files=files, data=data)
results = response.json()

for i, result in enumerate(results):
    if result['success']:
        print(f"å›¾ç‰‡ {i+1}: {result['text'][:100]}...")
```

### æç¤ºè¯æ¨¡æ¿

æ ¹æ®ä¸åŒåœºæ™¯é€‰æ‹©åˆé€‚çš„æç¤ºè¯ï¼š

```python
# æ–‡æ¡£è½¬ Markdown
prompt = "<image>\n<|grounding|>Convert the document to markdown."

# é€šç”¨ OCR
prompt = "<image>\n<|grounding|>OCR this image."

# æ— å¸ƒå±€è¯†åˆ«
prompt = "<image>\nFree OCR."

# å›¾è¡¨è§£æ
prompt = "<image>\nParse the figure."

# è¯¦ç»†æè¿°
prompt = "<image>\nDescribe this image in detail."

# å®šä½æ–‡æœ¬
prompt = "<image>\nLocate <|ref|>ç›®æ ‡æ–‡æœ¬<|/ref|> in the image."
```

---

## â“ å¸¸è§é—®é¢˜

### 1. æ¨¡å‹ä¸‹è½½æ…¢æˆ–å¤±è´¥

**è§£å†³æ–¹æ¡ˆ:**
```bash
# è®¾ç½® Hugging Face é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com

# æˆ–æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹
git lfs install
git clone https://huggingface.co/deepseek-ai/DeepSeek-OCR
```

### 2. CUDA å†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ:**
- å‡å° `base_size` å’Œ `image_size` å‚æ•°
- ä½¿ç”¨æ›´å°çš„æ‰¹å¤„ç†å¤§å°
- å…³é—­å…¶ä»–å ç”¨ GPU çš„ç¨‹åº

### 3. Flash Attention å®‰è£…å¤±è´¥

**è§£å†³æ–¹æ¡ˆ:**
```bash
# ç¡®ä¿å®‰è£…äº†æ­£ç¡®çš„ CUDA å·¥å…·é“¾
pip install flash-attn==2.7.3 --no-build-isolation

# å¦‚æœä»ç„¶å¤±è´¥ï¼Œå¯ä»¥è·³è¿‡ flash-attention
# ä¿®æ”¹ api_server.py ä¸­çš„ _attn_implementation='eager'
```

### 4. Docker GPU ä¸å¯ç”¨

**è§£å†³æ–¹æ¡ˆ:**
```bash
# æ£€æŸ¥ NVIDIA Container Toolkit
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi

# ç¡®ä¿ docker-compose.yml ä¸­é…ç½®äº† GPU
```

### 5. Windows ä¸Š Docker æ€§èƒ½é—®é¢˜

**è§£å†³æ–¹æ¡ˆ:**
- ä½¿ç”¨ WSL2 åç«¯
- åœ¨ Docker Desktop è®¾ç½®ä¸­åˆ†é…è¶³å¤Ÿçš„èµ„æº
- è€ƒè™‘ä½¿ç”¨æœ¬åœ°éƒ¨ç½²è€Œé Docker

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹å¤„ç†ä¼˜åŒ–

```python
# ä½¿ç”¨æ‰¹é‡æ¥å£å¤„ç†å¤šå¼ å›¾ç‰‡
files = [('files', open(f'image_{i}.jpg', 'rb')) for i in range(10)]
response = requests.post(url, files=files)
```

### 2. æ¨¡å‹ç¼“å­˜

```bash
# æŒ‚è½½æ¨¡å‹ç¼“å­˜ç›®å½•ï¼Œé¿å…é‡å¤ä¸‹è½½
docker-compose.yml ä¸­å·²é…ç½®:
volumes:
  - ./models:/root/.cache/huggingface
```

### 3. å¹¶å‘å¤„ç†

```python
# ä½¿ç”¨å¤šçº¿ç¨‹/å¤šè¿›ç¨‹å¤„ç†å¤šä¸ªè¯·æ±‚
from concurrent.futures import ThreadPoolExecutor

with ThreadPoolExecutor(max_workers=4) as executor:
    futures = [executor.submit(process_image, img) for img in images]
    results = [f.result() for f in futures]
```

---

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·ï¼š
1. æŸ¥çœ‹æ—¥å¿—: `docker-compose logs -f`
2. æ£€æŸ¥ GPU çŠ¶æ€: `nvidia-smi`
3. è®¿é—®é¡¹ç›® GitHub: https://github.com/deepseek-ai/DeepSeek-OCR

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ª MIT è®¸å¯è¯ã€‚è¯¦è§ LICENSE æ–‡ä»¶ã€‚

